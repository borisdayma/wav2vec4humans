program: run_common_voice.py
project: xlsr-en-punctuation
method: random
metric:
  name: test/cer
  goal: minimize
parameters:
  attention_dropout:
    distribution: log_uniform
    # from 0.1/5 to 0.1*5 - values provided are ln(min) -> ln(max)
    min: -3.9
    max: -0.7
  activation_dropout:
    distribution: log_uniform
    min: -3.9
    max: -0.7
  hidden_dropout:
    distribution: log_uniform
    min: -3.9
    max: -0.7
  feat_proj_dropout:
    distribution: log_uniform
    min: -3.9
    max: -0.7
  mask_time_prob:
    distribution: log_uniform
    min: -3.9
    max: -1.6
  layerdrop:
    distribution: log_uniform
    # from 0.05/2 to 0.05*2 - values provided are ln(min) -> ln(max)
    min: -4.6
    max: -1.6
  learning_rate:
    distribution: log_uniform
    min: -9.2
    max: -6.9
  gradient_accumulation_steps:
    distribution: int_uniform
    min: 2
    max: 4
command:
  - python
  - ${program}
  - "--model_name_or_path"
  - "facebook/wav2vec2-large-xlsr-53"
  - "--dataset_config_name"
  - "en"
  # we only train on 10% of data
  - "--train_split_name"
  - "train[:10%]"
  - "--output_dir"
  - "./model"
  - "--overwrite_output_dir"
  - "--num_train_epochs"
  - 3
  - "--per_device_train_batch_size"
  - 16
  - "--per_device_eval_batch_size"
  - 8
  - "--evaluation_strategy"
  - "epoch"
  - "--fp16"
  - "--freeze_feature_extractor"
  - "--group_by_length"
  - "--gradient_checkpointing"
  - "--do_train"
  - "--do_eval"
  - "--save_total_limit"
  - 1
  - "--logging_steps"
  - 100
  - "--warmup_steps"
  - 500
  - "--load_best_model_at_end"
  - "--metric_for_best_model"
  - "cer"
  - "--greater_is_better"
  - "False"
  - ${args}